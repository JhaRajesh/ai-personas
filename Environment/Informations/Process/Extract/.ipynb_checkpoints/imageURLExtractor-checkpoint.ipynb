{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50,50) into shape (100,100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-066876c16439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mimageURLExtractor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageURLExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minformation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mimageURLExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputLayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputTransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-066876c16439>\u001b[0m in \u001b[0;36mX_train_data\u001b[0;34m(self, inputTransform)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (50,50) into shape (100,100)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "\n",
    "class ImageURLExtractor(object):\n",
    "    \n",
    "    #default image size and dimension\n",
    "    img_rows, img_cols, dim = 100, 100, 1\n",
    "    \n",
    "    def __init__(self, information):\n",
    "        self.information = information\n",
    "    \n",
    "    def X_train_data(self, inputTransform):\n",
    "        no_of_images = len(self.information.trainingDataList)\n",
    "        data = np.random.random((no_of_images, self.dim, inputTransform.transformSize[0].dimensionSize, inputTransform.transformSize[1].dimensionSize))\n",
    "        image_index = 0\n",
    "        \n",
    "        if self.information.extractor == type(self).__name__:\n",
    "            for trainingData in self.information.trainingDataList:\n",
    "                response = requests.get(trainingData.URL)\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                \n",
    "                #FIXME: move transformer to transform package\n",
    "                img_rows = inputTransform.transformSize[0].dimensionSize\n",
    "                img_cols = inputTransform.transformSize[1].dimensionSize\n",
    "                img = img.resize((img_rows,img_cols), Image.ANTIALIAS)\n",
    "                \n",
    "                for parameter in inputTransform.transformParam:\n",
    "                    if parameter.parameterName == 'color':\n",
    "                        if parameter.parameterValue == 'grey':\n",
    "                            img = img.convert(\"L\")         \n",
    "                        if parameter.parameterName == 'process':\n",
    "                            if parameter.parameterValue == 'edge':\n",
    "                                img = img.filter(ImageFilter.FIND_EDGES)\n",
    "                            \n",
    "                img = np.asarray(img, dtype=np.float32)     \n",
    "                data[image_index, 0, :, :] = img\n",
    "                print (img.shape)\n",
    "                print (trainingData.URL)\n",
    "                \n",
    "        else:\n",
    "            print (\"Extractor in the information file and running extractor is not matching.\")\n",
    "        return data\n",
    "    \n",
    "    def Y_train_data(self, inputTransform):\n",
    "        print (self.information.extractor)\n",
    "        return\n",
    "    \n",
    "    def X_action_data(self, inputTransform):\n",
    "        print (self.information.extractor)\n",
    "        return   \n",
    "\n",
    "import scientists_pb2\n",
    "import sys\n",
    "import personaDefinition_pb2\n",
    "\n",
    "information = scientists_pb2.Information()\n",
    "\n",
    "persona = personaDefinition_pb2.Persona()\n",
    "dna = persona.DNAs.add()\n",
    "inputLayer = dna.inputs.add()\n",
    "inputLayer.inputTransform.transformerName = \"imageTransform\"\n",
    "inputLayer.inputTransform.informationType = \"image\"\n",
    "transformInputSize1 =  inputLayer.inputTransform.transformSize.add()\n",
    "transformInputSize1.dimension = 1\n",
    "transformInputSize1.dimensionSize = 50\n",
    "transformInputSize2 =  inputLayer.inputTransform.transformSize.add()\n",
    "transformInputSize2.dimension = 1\n",
    "transformInputSize2.dimensionSize = 50\n",
    "transformParam1 = inputLayer.inputTransform.transformParam.add()\n",
    "transformParam1.parameterName = \"color\"\n",
    "transformParam1.parameterValue  = \"grey\"\n",
    "transformParam2 = inputLayer.inputTransform.transformParam.add()\n",
    "transformParam2.parameterName = \"process\"\n",
    "transformParam2.parameterValue  = \"edge\"\n",
    "    \n",
    "# Read the existing address book.\n",
    "f = open(\"test.bin\", \"rb\")\n",
    "information.ParseFromString(f.read())\n",
    "f.close()\n",
    "\n",
    "imageURLExtractor = ImageURLExtractor(information)\n",
    "imageURLExtractor.X_train_data(inputLayer.inputTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
