{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image, ImageFilter\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rames\\Documents\\GitHub\\ai-personas\\Personas\\personaDefinition_pb2.py\n",
      "imageInput\n",
      "(50L, 50L)\n",
      "http://www.loc.gov/rr/scitech/subjectguides/images/tesla-new.jpg\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd660e4b089801fe7e3d9/1458152617516/SciSource_BK0929.jpg?format=750w\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd28be4b0c47638e2f540/1458152692173/SciSource_BN4337.jpg?format=750w\n",
      "input\n",
      "(1L, 50L, 50L)\n",
      "conv2D\n",
      "activation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '7044' (I am process '644')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout\n",
      "(1L, 50L, 50L)\n",
      "conv2D\n",
      "activation\n",
      "dropout\n",
      "(1L, 50L, 50L)\n",
      "conv2D\n",
      "activation\n",
      "(50L, 50L)\n",
      "http://www.loc.gov/rr/scitech/subjectguides/images/tesla-new.jpg\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd660e4b089801fe7e3d9/1458152617516/SciSource_BK0929.jpg?format=750w\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd28be4b0c47638e2f540/1458152692173/SciSource_BN4337.jpg?format=750w\n",
      "output\n",
      "(3L, 1L, 50L, 50L)\n",
      "(3L, 1L, 50L, 50L)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 100L, 50L, 50L 1000        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 100L, 50L, 50L 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100L, 50L, 50L 0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 100L, 50L, 50L 90100       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 100L, 50L, 50L 0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100L, 50L, 50L 0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 1L, 50L, 50L)  901         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1L, 50L, 50L)  0           convolution2d_3[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 92,001\n",
      "Trainable params: 92,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "3\n",
      "Train on 3 samples, validate on 3 samples\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s - loss: -38.0285 - val_loss: -384.3273\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s - loss: -354.7856 - val_loss: -407.1480\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s - loss: -375.8128 - val_loss: -407.2743\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s - loss: -395.4159 - val_loss: -407.5227\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s - loss: -398.2420 - val_loss: -407.5493\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s - loss: -400.8809 - val_loss: -407.7973\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s - loss: -401.8628 - val_loss: -407.8036\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s - loss: -401.1971 - val_loss: -407.8115\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s - loss: -403.8007 - val_loss: -407.8302\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s - loss: -405.9007 - val_loss: -407.8374\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s - loss: -404.9741 - val_loss: -407.8402\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s - loss: -404.8981 - val_loss: -407.8496\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s - loss: -405.1709 - val_loss: -407.8509\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s - loss: -406.2579 - val_loss: -407.8590\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s - loss: -405.7928 - val_loss: -407.8616\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s - loss: -406.2788 - val_loss: -407.8625\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s - loss: -406.9461 - val_loss: -407.8635\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s - loss: -406.8375 - val_loss: -407.8662\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s - loss: -406.4669 - val_loss: -407.8676\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s - loss: -407.7134 - val_loss: -407.8687\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s - loss: -406.6472 - val_loss: -407.8701\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s - loss: -406.7877 - val_loss: -407.8711\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s - loss: -405.9299 - val_loss: -407.8750\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s - loss: -407.4990 - val_loss: -407.8773\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s - loss: -405.4676 - val_loss: -407.8794\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s - loss: -406.4050 - val_loss: -407.8824\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s - loss: -407.3037 - val_loss: -407.8835\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s - loss: -406.7395 - val_loss: -407.8860\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s - loss: -407.2714 - val_loss: -407.8870\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s - loss: -407.0602 - val_loss: -407.8888\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s - loss: -406.2826 - val_loss: -407.8900\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s - loss: -407.0107 - val_loss: -407.8927\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s - loss: -406.7595 - val_loss: -407.8936\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s - loss: -407.8086 - val_loss: -407.8949\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s - loss: -406.8403 - val_loss: -407.8958\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s - loss: -407.0898 - val_loss: -407.8969\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s - loss: -407.3156 - val_loss: -407.8981\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s - loss: -407.3987 - val_loss: -407.8990\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s - loss: -407.3316 - val_loss: -407.9001\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s - loss: -407.6912 - val_loss: -407.9011\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s - loss: -407.5180 - val_loss: -407.9047\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s - loss: -407.6931 - val_loss: -407.9056\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s - loss: -406.9259 - val_loss: -407.9066\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s - loss: -407.8822 - val_loss: -407.9077\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s - loss: -407.5990 - val_loss: -407.9087\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s - loss: -407.3079 - val_loss: -407.9121\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s - loss: -407.8888 - val_loss: -407.9132\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s - loss: -407.4080 - val_loss: -407.9146\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s - loss: -407.8552 - val_loss: -407.9171\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s - loss: -407.4314 - val_loss: -407.9181\n"
     ]
    }
   ],
   "source": [
    "#persona definition\n",
    "persona_definition_path = os.path.abspath(os.path.join('..', '..', 'Personas', 'personaDefinition_pb2.py'))\n",
    "print (persona_definition_path)\n",
    "#import persona proto modules\n",
    "persona = imp.load_source('Persona', persona_definition_path).Persona()\n",
    "\n",
    "#load persona\n",
    "personaName = \"Khandhasamy\"\n",
    "personaCategory = ['Artist', 'Portraits', 'sketchToGreyImage'] \n",
    "personaPath = os.path.join('..', '..', 'Personas')\n",
    "for category in personaCategory:\n",
    "    personaPath = os.path.join(personaPath, category)\n",
    "\n",
    "#persona file\n",
    "persona_abs_path = os.path.abspath(os.path.join(personaPath, personaName , personaName + '.bin'))\n",
    "f = open(persona_abs_path, \"rb\")\n",
    "persona.ParseFromString(f.read())\n",
    "\n",
    "def getInformationSource(persona, layer):\n",
    "    for environment in persona.age.environments:\n",
    "        for information in environment.informations:\n",
    "            for informationConnectedLayerName in information.connectedLayerName:\n",
    "                if (layer.layerName == informationConnectedLayerName):\n",
    "                    #print (information.informationSource)\n",
    "                    return getExtractor(information)\n",
    "\n",
    "def getExtractor(information):\n",
    "    #information definition\n",
    "    information_definition_path = os.path.abspath(os.path.join('..', '..', 'Environment', information.informationSource + \"_pb2.py\"))\n",
    "    informationModule = imp.load_source('Information', information_definition_path).Information()  \n",
    "    information_file_path = os.path.abspath(os.path.join('..', '..', 'Environment', information.informationSource + \".bin\"))\n",
    "    informationFile = open(information_file_path, \"rb\")\n",
    "    informationModule.ParseFromString(informationFile.read())\n",
    "    #load extractor\n",
    "    information_extractor_path = os.path.abspath(os.path.join('..', '..', 'Environment/Informations/Process/Extract/' + informationModule.extractor + \".py\"))\n",
    "    extractorModule = imp.load_source(informationModule.extractor, information_extractor_path).ImageURLExtractor(informationModule)\n",
    "    #print (informationModule.extractor)\n",
    "    return extractorModule\n",
    "\n",
    "LAYER_CONVOLUTION = \"layerConvolution\"\n",
    "LAYER_ACTIVATION = \"layerActivation\"\n",
    "LAYER_DROPOUT = \"layerDropout\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "def runPersona(persona):\n",
    "    x_train_data = None\n",
    "    y_train_data = None\n",
    "    x_action_data = None\n",
    "    input_shape = None\n",
    "    batch_size = None\n",
    "\n",
    "    for dna in persona.DNAs:\n",
    "        for inputLayer in dna.inputs:\n",
    "            print (inputLayer.layerName)\n",
    "            inputTransform = inputLayer.inputTransform\n",
    "            #get information source\n",
    "            information = getInformationSource(persona, inputLayer)\n",
    "\n",
    "            x_train_data = information.getData(inputTransform)\n",
    "            #x_action_data = information.get_data(inputTransform)\n",
    "            print (\"input\")\n",
    "            \n",
    "        for layer in dna.layers:\n",
    "            if (LAYER_CONVOLUTION == layer.WhichOneof(\"SubLayer\")):\n",
    "                nb_filters = layer.layerConvolution.filters\n",
    "                convDimension = layer.layerConvolution.convolutionDimension\n",
    "                borderMode = layer.layerConvolution.borderMode\n",
    "                kernelSize = layer.layerConvolution.kernelSize\n",
    "                inputShape = layer.layerConvolution.inputShape\n",
    "                if K.image_dim_ordering() == 'th':\n",
    "                    conv_input_shape = (inputShape[0], inputShape[1], inputShape[2])\n",
    "                else:\n",
    "                    conv_input_shape = (inputShape[1], inputShape[2], inputShape[0])\n",
    "                if convDimension == 2:\n",
    "                    model.add(Convolution2D(nb_filters, kernelSize[0], kernelSize[1],\n",
    "                        border_mode=borderMode,\n",
    "                        input_shape=conv_input_shape))\n",
    "                    print (conv_input_shape)\n",
    "                    print (\"conv2D\")\n",
    "            if (LAYER_ACTIVATION == layer.WhichOneof(\"SubLayer\")):  \n",
    "                activationType = layer.layerActivation.activationType\n",
    "                model.add(Activation(activationType))\n",
    "                print (\"activation\")\n",
    "            if (LAYER_DROPOUT == layer.WhichOneof(\"SubLayer\")):\n",
    "                dropoutPercentage = layer.layerDropout.dropPercentage\n",
    "                model.add(Dropout(dropoutPercentage))\n",
    "                print (\"dropout\")\n",
    "                \n",
    "        for outputLayer in dna.outputs:\n",
    "            #print (outputLayer.layerName)\n",
    "            inputTransform = outputLayer.inputTransform\n",
    "            #get information source\n",
    "            information = getInformationSource(persona, outputLayer)\n",
    "            #train data\n",
    "            y_train_data = information.getData(inputTransform)\n",
    "            print (\"output\")\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "    \n",
    "    print (x_train_data.shape)\n",
    "    print (y_train_data.shape)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    #learning\n",
    "    batch_size = persona.age.learningBatchSize\n",
    "    print (batch_size)\n",
    "    nb_epoch = 50\n",
    "    model.fit(x_train_data, y_train_data, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(x_train_data, y_train_data))\n",
    "    \n",
    "    #output for given input\n",
    "    #output_data = model.predict(x_action_data)\n",
    "    \n",
    "runPersona(persona)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
