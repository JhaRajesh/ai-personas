{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Model loaded.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, None, None, 64 1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, None, None, 64 36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, None, None, 64 0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, None, None, 12 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, None, None, 12 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 12 0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, None, None, 25 295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, None, None, 25 590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, None, None, 25 590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 25 0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, None, None, 51 1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, None, None, 51 2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, None, None, 51 2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 51 0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, None, None, 51 2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, None, None, 51 2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, None, None, 51 2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, None, None, 51 0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Processing filter 0\n",
      "Current loss value: 12.2799072266\n",
      "Current loss value: 24.5395145416\n",
      "Current loss value: 47.0157318115\n",
      "Current loss value: 70.5969161987\n",
      "Current loss value: 90.6072540283\n",
      "Current loss value: 112.008705139\n",
      "Current loss value: 132.025939941\n",
      "Current loss value: 155.923690796\n",
      "Current loss value: 177.083145142\n",
      "Current loss value: 198.956542969\n",
      "Current loss value: 217.961746216\n",
      "Current loss value: 241.145004272\n",
      "Current loss value: 262.036560059\n",
      "Current loss value: 286.59664917\n",
      "Current loss value: 307.893981934\n",
      "Current loss value: 333.711700439\n",
      "Current loss value: 355.867919922\n",
      "Current loss value: 380.411621094\n",
      "Current loss value: 403.316833496\n",
      "Current loss value: 424.185913086\n",
      "Filter 0 processed in 43s\n",
      "Processing filter 1\n",
      "Current loss value: 0.0\n",
      "Filter 1 processed in 2s\n",
      "Processing filter 2\n",
      "Current loss value: 7.68990707397\n",
      "Current loss value: 24.1448860168\n",
      "Current loss value: 56.1322898865\n",
      "Current loss value: 94.2820968628\n",
      "Current loss value: 121.556968689\n",
      "Current loss value: 154.388946533\n",
      "Current loss value: 179.887176514\n",
      "Current loss value: 211.06930542\n",
      "Current loss value: 236.246261597\n",
      "Current loss value: 270.416442871\n",
      "Current loss value: 296.477478027\n",
      "Current loss value: 327.038085938\n",
      "Current loss value: 357.208282471\n",
      "Current loss value: 383.603912354\n",
      "Current loss value: 410.375946045\n",
      "Current loss value: 439.009216309\n",
      "Current loss value: 465.755523682\n",
      "Current loss value: 491.692504883\n",
      "Current loss value: 525.278442383\n",
      "Current loss value: 550.967041016\n",
      "Filter 2 processed in 15s\n",
      "Processing filter 3\n",
      "Current loss value: 13.0693397522\n",
      "Current loss value: 43.4564781189\n",
      "Current loss value: 112.053260803\n",
      "Current loss value: 197.874542236\n",
      "Current loss value: 282.36895752\n",
      "Current loss value: 348.190979004\n",
      "Current loss value: 410.406890869\n",
      "Current loss value: 464.799987793\n",
      "Current loss value: 522.496887207\n",
      "Current loss value: 575.040100098\n",
      "Current loss value: 625.249511719\n",
      "Current loss value: 677.587402344\n",
      "Current loss value: 727.273925781\n",
      "Current loss value: 776.559082031\n",
      "Current loss value: 826.534240723\n",
      "Current loss value: 871.851257324\n",
      "Current loss value: 918.15423584\n",
      "Current loss value: 966.318603516\n",
      "Current loss value: 1014.20758057\n",
      "Current loss value: 1057.62963867\n",
      "Filter 3 processed in 26s\n",
      "Processing filter 4\n",
      "Current loss value: 8.98799991608\n",
      "Current loss value: 47.147354126\n",
      "Current loss value: 89.7309112549\n",
      "Current loss value: 135.755813599\n",
      "Current loss value: 177.529907227\n",
      "Current loss value: 221.870132446\n",
      "Current loss value: 269.437561035\n",
      "Current loss value: 310.202972412\n",
      "Current loss value: 353.929748535\n",
      "Current loss value: 395.259613037\n",
      "Current loss value: 440.306030273\n",
      "Current loss value: 487.613769531\n",
      "Current loss value: 537.815307617\n",
      "Current loss value: 586.990905762\n",
      "Current loss value: 631.938476562\n",
      "Current loss value: 677.084594727\n",
      "Current loss value: 722.922485352\n",
      "Current loss value: 766.510192871\n",
      "Current loss value: 812.714660645\n",
      "Current loss value: 859.115539551\n",
      "Filter 4 processed in 14s\n",
      "Processing filter 5\n",
      "Current loss value: 28.6697807312\n",
      "Current loss value: 48.8363952637\n",
      "Current loss value: 75.2372970581\n",
      "Current loss value: 100.800354004\n",
      "Current loss value: 142.370315552\n",
      "Current loss value: 185.67427063\n",
      "Current loss value: 233.719955444\n",
      "Current loss value: 275.730957031\n",
      "Current loss value: 317.304077148\n",
      "Current loss value: 354.773345947\n",
      "Current loss value: 397.53112793\n",
      "Current loss value: 434.43637085\n",
      "Current loss value: 468.18927002\n",
      "Current loss value: 508.836975098\n",
      "Current loss value: 551.331848145\n",
      "Current loss value: 589.193664551\n",
      "Current loss value: 633.521057129\n",
      "Current loss value: 668.903320312\n",
      "Current loss value: 709.399169922\n",
      "Current loss value: 743.386962891\n",
      "Filter 5 processed in 14s\n",
      "Processing filter 6\n",
      "Current loss value: 0.0390751883388\n",
      "Current loss value: 3.85447359085\n",
      "Current loss value: 22.2979621887\n",
      "Current loss value: 37.5399208069\n",
      "Current loss value: 55.3036499023\n",
      "Current loss value: 80.4627380371\n",
      "Current loss value: 112.433517456\n",
      "Current loss value: 148.688552856\n",
      "Current loss value: 195.898788452\n",
      "Current loss value: 246.964401245\n",
      "Current loss value: 310.282806396\n",
      "Current loss value: 367.069335938\n",
      "Current loss value: 426.661621094\n",
      "Current loss value: 479.469055176\n",
      "Current loss value: 536.068237305\n",
      "Current loss value: 590.538635254\n",
      "Current loss value: 642.841491699\n",
      "Current loss value: 691.723876953\n",
      "Current loss value: 738.032470703\n",
      "Current loss value: 781.47833252\n",
      "Filter 6 processed in 14s\n",
      "Processing filter 7\n",
      "Current loss value: 3.56979107857\n",
      "Current loss value: 10.627325058\n",
      "Current loss value: 25.0339107513\n",
      "Current loss value: 60.8269996643\n",
      "Current loss value: 104.816108704\n",
      "Current loss value: 144.118759155\n",
      "Current loss value: 188.757232666\n",
      "Current loss value: 237.821487427\n",
      "Current loss value: 288.259155273\n",
      "Current loss value: 336.86630249\n",
      "Current loss value: 384.647277832\n",
      "Current loss value: 435.691558838\n",
      "Current loss value: 476.65838623\n",
      "Current loss value: 527.67590332\n",
      "Current loss value: 576.27557373\n",
      "Current loss value: 620.421936035\n",
      "Current loss value: 674.251708984\n",
      "Current loss value: 727.387329102\n",
      "Current loss value: 784.725280762\n",
      "Current loss value: 836.903625488\n",
      "Filter 7 processed in 13s\n",
      "Processing filter 8\n",
      "Current loss value: 100.430274963\n",
      "Current loss value: 166.244552612\n",
      "Current loss value: 255.928451538\n",
      "Current loss value: 361.98727417\n",
      "Current loss value: 437.751556396\n",
      "Current loss value: 517.216247559\n",
      "Current loss value: 593.046081543\n",
      "Current loss value: 668.542053223\n",
      "Current loss value: 739.065307617\n",
      "Current loss value: 811.403808594\n",
      "Current loss value: 880.429626465\n",
      "Current loss value: 945.358520508\n",
      "Current loss value: 1011.88897705\n",
      "Current loss value: 1073.33520508\n",
      "Current loss value: 1135.8470459\n",
      "Current loss value: 1196.40979004\n",
      "Current loss value: 1256.6796875\n",
      "Current loss value: 1319.0402832\n",
      "Current loss value: 1375.67016602\n",
      "Current loss value: 1436.4465332\n",
      "Filter 8 processed in 14s\n",
      "Processing filter 9\n",
      "Current loss value: 14.6935100555\n",
      "Current loss value: 74.1670761108\n",
      "Current loss value: 76.9577331543\n",
      "Current loss value: 150.849960327\n",
      "Current loss value: 190.031005859\n",
      "Current loss value: 230.738739014\n",
      "Current loss value: 320.081176758\n",
      "Current loss value: 366.93572998\n",
      "Current loss value: 430.105987549\n",
      "Current loss value: 449.877166748\n",
      "Current loss value: 500.397918701\n",
      "Current loss value: 553.658935547\n",
      "Current loss value: 584.795959473\n",
      "Current loss value: 650.282775879\n",
      "Current loss value: 669.858764648\n",
      "Current loss value: 726.145263672\n",
      "Current loss value: 767.424316406\n",
      "Current loss value: 798.225708008\n",
      "Current loss value: 842.032592773\n",
      "Current loss value: 873.366882324\n",
      "Filter 9 processed in 14s\n",
      "Processing filter 10\n",
      "Current loss value: 9.03728675842\n",
      "Current loss value: 12.1810054779\n",
      "Current loss value: 32.4671211243\n",
      "Current loss value: 63.4628257751\n",
      "Current loss value: 96.4778823853\n",
      "Current loss value: 135.113876343\n",
      "Current loss value: 178.072906494\n",
      "Current loss value: 226.285888672\n",
      "Current loss value: 274.680999756\n",
      "Current loss value: 314.714202881\n",
      "Current loss value: 347.194885254\n",
      "Current loss value: 387.322052002\n",
      "Current loss value: 415.719818115\n",
      "Current loss value: 450.91104126\n",
      "Current loss value: 494.828155518\n",
      "Current loss value: 535.398742676\n",
      "Current loss value: 573.584777832\n",
      "Current loss value: 615.187072754\n",
      "Current loss value: 642.856201172\n",
      "Current loss value: 687.331176758\n",
      "Filter 10 processed in 15s\n",
      "Processing filter 11\n",
      "Current loss value: 3.40945291519\n",
      "Current loss value: 7.82999181747\n",
      "Current loss value: 35.0343132019\n",
      "Current loss value: 100.745162964\n",
      "Current loss value: 181.016143799\n",
      "Current loss value: 261.775482178\n",
      "Current loss value: 342.199371338\n",
      "Current loss value: 417.386627197\n",
      "Current loss value: 490.136047363\n",
      "Current loss value: 560.661010742\n",
      "Current loss value: 621.884216309\n",
      "Current loss value: 686.947570801\n",
      "Current loss value: 744.687255859\n",
      "Current loss value: 804.16217041\n",
      "Current loss value: 861.687133789\n",
      "Current loss value: 914.678344727\n",
      "Current loss value: 973.593994141\n",
      "Current loss value: 1028.74316406\n",
      "Current loss value: 1085.83447266\n",
      "Current loss value: 1143.74975586\n",
      "Filter 11 processed in 15s\n",
      "Processing filter 12\n",
      "Current loss value: 0.0\n",
      "Filter 12 processed in 2s\n",
      "Processing filter 13\n",
      "Current loss value: 10.4648761749\n",
      "Current loss value: 70.4862442017\n",
      "Current loss value: 117.268455505\n",
      "Current loss value: 156.224105835\n",
      "Current loss value: 193.617340088\n",
      "Current loss value: 223.755325317\n",
      "Current loss value: 264.174133301\n",
      "Current loss value: 297.502929688\n",
      "Current loss value: 328.328857422\n",
      "Current loss value: 353.41305542\n",
      "Current loss value: 388.702575684\n",
      "Current loss value: 418.042999268\n",
      "Current loss value: 445.185699463\n",
      "Current loss value: 471.234069824\n",
      "Current loss value: 499.171417236\n",
      "Current loss value: 528.917297363\n",
      "Current loss value: 551.355957031\n",
      "Current loss value: 579.40612793\n",
      "Current loss value: 604.975708008\n",
      "Current loss value: 629.082458496\n",
      "Filter 13 processed in 15s\n",
      "Processing filter 14\n",
      "Current loss value: 3.90627980232\n",
      "Current loss value: 32.320640564\n",
      "Current loss value: 89.8933181763\n",
      "Current loss value: 150.56199646\n",
      "Current loss value: 211.293838501\n",
      "Current loss value: 268.211212158\n",
      "Current loss value: 319.579772949\n",
      "Current loss value: 373.035827637\n",
      "Current loss value: 434.179168701\n",
      "Current loss value: 488.099822998\n",
      "Current loss value: 530.530883789\n",
      "Current loss value: 580.340393066\n",
      "Current loss value: 632.627319336\n",
      "Current loss value: 682.600402832\n",
      "Current loss value: 732.705505371\n",
      "Current loss value: 776.798217773\n",
      "Current loss value: 822.86340332\n",
      "Current loss value: 864.205444336\n",
      "Current loss value: 912.261657715\n",
      "Current loss value: 952.94934082\n",
      "Filter 14 processed in 19s\n",
      "Processing filter 15\n",
      "Current loss value: 0.349721848965\n",
      "Current loss value: 5.97099304199\n",
      "Current loss value: 19.5777759552\n",
      "Current loss value: 36.5461425781\n",
      "Current loss value: 64.7524108887\n",
      "Current loss value: 96.7095947266\n",
      "Current loss value: 136.815124512\n",
      "Current loss value: 174.569992065\n",
      "Current loss value: 210.099609375\n",
      "Current loss value: 255.09437561\n",
      "Current loss value: 300.420776367\n",
      "Current loss value: 347.267700195\n",
      "Current loss value: 389.429290771\n",
      "Current loss value: 427.454559326\n",
      "Current loss value: 462.69329834\n",
      "Current loss value: 498.072784424\n",
      "Current loss value: 533.880432129\n",
      "Current loss value: 571.912658691\n",
      "Current loss value: 606.250244141\n",
      "Current loss value: 644.395568848\n",
      "Filter 15 processed in 15s\n",
      "Processing filter 16\n",
      "Current loss value: 0.0160207804292\n",
      "Current loss value: 9.63048744202\n",
      "Current loss value: 12.4477825165\n",
      "Current loss value: 37.2733955383\n",
      "Current loss value: 63.330696106\n",
      "Current loss value: 91.6301193237\n",
      "Current loss value: 121.297142029\n",
      "Current loss value: 149.166397095\n",
      "Current loss value: 185.829116821\n",
      "Current loss value: 215.94418335\n",
      "Current loss value: 254.458206177\n",
      "Current loss value: 289.764556885\n",
      "Current loss value: 332.894165039\n",
      "Current loss value: 367.867889404\n",
      "Current loss value: 408.941894531\n",
      "Current loss value: 445.233428955\n",
      "Current loss value: 483.610900879\n",
      "Current loss value: 520.519775391\n",
      "Current loss value: 567.830322266\n",
      "Current loss value: 610.177124023\n",
      "Filter 16 processed in 17s\n",
      "Processing filter 17\n",
      "Current loss value: 1.26942813396\n",
      "Current loss value: 13.1739397049\n",
      "Current loss value: 36.992225647\n",
      "Current loss value: 74.4520568848\n",
      "Current loss value: 122.069229126\n",
      "Current loss value: 176.861968994\n",
      "Current loss value: 227.817153931\n",
      "Current loss value: 279.176269531\n",
      "Current loss value: 336.52456665\n",
      "Current loss value: 395.574615479\n",
      "Current loss value: 459.735198975\n",
      "Current loss value: 522.883911133\n",
      "Current loss value: 581.16619873\n",
      "Current loss value: 636.296875\n",
      "Current loss value: 696.55480957\n",
      "Current loss value: 758.471618652\n",
      "Current loss value: 814.758728027\n",
      "Current loss value: 870.596801758\n",
      "Current loss value: 922.450012207\n",
      "Current loss value: 972.381591797\n",
      "Filter 17 processed in 16s\n",
      "Processing filter 18\n",
      "Current loss value: 37.6844406128\n",
      "Current loss value: 182.779403687\n",
      "Current loss value: 322.274627686\n",
      "Current loss value: 433.310302734\n",
      "Current loss value: 501.976928711\n",
      "Current loss value: 567.79864502\n",
      "Current loss value: 626.45300293\n",
      "Current loss value: 671.357971191\n",
      "Current loss value: 727.114929199\n",
      "Current loss value: 773.86529541\n",
      "Current loss value: 825.033081055\n",
      "Current loss value: 870.932373047\n",
      "Current loss value: 918.526428223\n",
      "Current loss value: 956.305114746\n",
      "Current loss value: 1010.23150635\n",
      "Current loss value: 1051.20617676\n",
      "Current loss value: 1097.07580566\n",
      "Current loss value: 1137.99804688\n",
      "Current loss value: 1184.19030762\n",
      "Current loss value: 1225.55847168\n",
      "Filter 18 processed in 16s\n",
      "Processing filter 19\n",
      "Current loss value: 0.0\n",
      "Filter 19 processed in 2s\n",
      "Processing filter 20\n",
      "Current loss value: 23.7492961884\n",
      "Current loss value: 40.7118721008\n",
      "Current loss value: 70.2719039917\n",
      "Current loss value: 98.811340332\n",
      "Current loss value: 143.230209351\n",
      "Current loss value: 183.710113525\n",
      "Current loss value: 228.667572021\n",
      "Current loss value: 264.275024414\n",
      "Current loss value: 304.214996338\n",
      "Current loss value: 340.869445801\n",
      "Current loss value: 376.01473999\n",
      "Current loss value: 407.058746338\n",
      "Current loss value: 440.47946167\n",
      "Current loss value: 470.974060059\n",
      "Current loss value: 508.237365723\n",
      "Current loss value: 536.339233398\n",
      "Current loss value: 571.360473633\n",
      "Current loss value: 601.389770508\n",
      "Current loss value: 628.991027832\n",
      "Current loss value: 665.72845459\n",
      "Filter 20 processed in 15s\n",
      "Processing filter 21\n",
      "Current loss value: 0.0\n",
      "Filter 21 processed in 3s\n",
      "Processing filter 22\n",
      "Current loss value: 0.0\n",
      "Filter 22 processed in 2s\n",
      "Processing filter 23\n",
      "Current loss value: 16.183637619\n",
      "Current loss value: 32.9209098816\n",
      "Current loss value: 67.2115097046\n",
      "Current loss value: 106.047576904\n",
      "Current loss value: 150.907928467\n",
      "Current loss value: 206.053848267\n",
      "Current loss value: 257.995849609\n",
      "Current loss value: 317.78427124\n",
      "Current loss value: 366.76083374\n",
      "Current loss value: 412.019897461\n",
      "Current loss value: 457.181732178\n",
      "Current loss value: 498.356903076\n",
      "Current loss value: 536.152160645\n",
      "Current loss value: 574.302429199\n",
      "Current loss value: 612.223693848\n",
      "Current loss value: 652.205749512\n",
      "Current loss value: 684.753845215\n",
      "Current loss value: 722.794555664\n",
      "Current loss value: 762.190490723\n",
      "Current loss value: 798.248962402\n",
      "Filter 23 processed in 16s\n",
      "Processing filter 24\n",
      "Current loss value: 9.53378772736\n",
      "Current loss value: 37.6087684631\n",
      "Current loss value: 73.4295501709\n",
      "Current loss value: 114.569366455\n",
      "Current loss value: 154.804199219\n",
      "Current loss value: 193.239181519\n",
      "Current loss value: 231.813964844\n",
      "Current loss value: 272.137268066\n",
      "Current loss value: 307.016357422\n",
      "Current loss value: 346.193115234\n",
      "Current loss value: 386.58114624\n",
      "Current loss value: 427.870880127\n",
      "Current loss value: 464.82333374\n",
      "Current loss value: 508.608795166\n",
      "Current loss value: 552.531799316\n",
      "Current loss value: 589.213989258\n",
      "Current loss value: 625.993591309\n",
      "Current loss value: 668.38659668\n",
      "Current loss value: 703.491027832\n",
      "Current loss value: 740.786865234\n",
      "Filter 24 processed in 16s\n",
      "Processing filter 25\n",
      "Current loss value: 1.52732467651\n",
      "Current loss value: 13.6192789078\n",
      "Current loss value: 36.4665489197\n",
      "Current loss value: 69.7406616211\n",
      "Current loss value: 101.174743652\n",
      "Current loss value: 134.640350342\n",
      "Current loss value: 169.076416016\n",
      "Current loss value: 206.186935425\n",
      "Current loss value: 241.860183716\n",
      "Current loss value: 274.389373779\n",
      "Current loss value: 305.620361328\n",
      "Current loss value: 341.779571533\n",
      "Current loss value: 376.822113037\n",
      "Current loss value: 410.343231201\n",
      "Current loss value: 444.96194458\n",
      "Current loss value: 482.816802979\n",
      "Current loss value: 519.859985352\n",
      "Current loss value: 552.343688965\n",
      "Current loss value: 586.438232422\n",
      "Current loss value: 616.923217773\n",
      "Filter 25 processed in 15s\n",
      "Processing filter 26\n",
      "Current loss value: 0.0\n",
      "Filter 26 processed in 8s\n",
      "Processing filter 27\n",
      "Current loss value: 3.25236582756\n",
      "Current loss value: 5.59140253067\n",
      "Current loss value: 12.7099466324\n",
      "Current loss value: 27.1968841553\n",
      "Current loss value: 45.8675460815\n",
      "Current loss value: 75.3127670288\n",
      "Current loss value: 110.093544006\n",
      "Current loss value: 155.505630493\n",
      "Current loss value: 193.27911377\n",
      "Current loss value: 264.632720947\n",
      "Current loss value: 322.196868896\n",
      "Current loss value: 404.871582031\n",
      "Current loss value: 474.45703125\n",
      "Current loss value: 547.659606934\n",
      "Current loss value: 619.311523438\n",
      "Current loss value: 708.02935791\n",
      "Current loss value: 791.409362793\n",
      "Current loss value: 883.976135254\n",
      "Current loss value: 967.223999023\n",
      "Current loss value: 1060.47265625\n",
      "Filter 27 processed in 14s\n",
      "Processing filter 28\n",
      "Current loss value: 1.02002203465\n",
      "Current loss value: 18.1917304993\n",
      "Current loss value: 70.0055007935\n",
      "Current loss value: 135.707748413\n",
      "Current loss value: 201.493499756\n",
      "Current loss value: 256.83303833\n",
      "Current loss value: 316.099121094\n",
      "Current loss value: 364.352508545\n",
      "Current loss value: 411.338043213\n",
      "Current loss value: 452.27645874\n",
      "Current loss value: 488.907012939\n",
      "Current loss value: 536.156555176\n",
      "Current loss value: 572.84564209\n",
      "Current loss value: 614.307373047\n",
      "Current loss value: 655.850341797\n",
      "Current loss value: 698.782897949\n",
      "Current loss value: 735.937133789\n",
      "Current loss value: 776.711425781\n",
      "Current loss value: 812.90814209\n",
      "Current loss value: 850.405883789\n",
      "Filter 28 processed in 15s\n",
      "Processing filter 29\n",
      "Current loss value: 36.6403846741\n",
      "Current loss value: 56.6949806213\n",
      "Current loss value: 100.575157166\n",
      "Current loss value: 182.776626587\n",
      "Current loss value: 237.449493408\n",
      "Current loss value: 287.180084229\n",
      "Current loss value: 340.298156738\n",
      "Current loss value: 389.628662109\n",
      "Current loss value: 433.860931396\n",
      "Current loss value: 485.197662354\n",
      "Current loss value: 518.327209473\n",
      "Current loss value: 576.562683105\n",
      "Current loss value: 619.207824707\n",
      "Current loss value: 666.757873535\n",
      "Current loss value: 711.477966309\n",
      "Current loss value: 760.067199707\n",
      "Current loss value: 806.470581055\n",
      "Current loss value: 841.432739258\n",
      "Current loss value: 893.755432129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d48bfd9b549d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[1;31m# we run gradient ascent for 20 steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mloss_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_img_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0minput_img_data\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\rames\\Anaconda2\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\rames\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" This script demonstrates the use of a convolutional LSTM network.\n",
    "This network is used to predict the next frame of an artificially\n",
    "generated movie which contains moving squares.\n",
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "# We create a layer which take as input movies of shape\n",
    "# (n_frames, width, height, channels) and returns a movie\n",
    "# of identical shape.\n",
    "\n",
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n",
    "                   input_shape=(None, 40, 40, 1),\n",
    "                   border_mode='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n",
    "                   border_mode='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n",
    "                   border_mode='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n",
    "                   border_mode='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Convolution3D(nb_filter=1, kernel_dim1=1, kernel_dim2=3,\n",
    "                      kernel_dim3=3, activation='sigmoid',\n",
    "                      border_mode='same', dim_ordering='tf'))\n",
    "\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "\n",
    "\n",
    "# Artificial data generation:\n",
    "# Generate movies with 3 to 7 moving squares inside.\n",
    "# The squares are of shape 1x1 or 2x2 pixels,\n",
    "# which move linearly over time.\n",
    "# For convenience we first create movies with bigger width and height (80x80)\n",
    "# and at the end we select a 40x40 window.\n",
    "\n",
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "# Train the network\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
    "        nb_epoch=300, validation_split=0.05)\n",
    "\n",
    "# Testing the network on one movie\n",
    "# feed it with the first 7 positions and then\n",
    "# predict the new positions\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "\n",
    "\n",
    "# And then compare the predictions\n",
    "# to the ground truth\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Inital trajectory', fontsize=20)\n",
    "\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    plt.savefig('%i_animate.png' % (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
