{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image, ImageFilter\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rames\\Documents\\GitHub\\ai-personas\\Personas\\personaDefinition_pb2.py\n",
      "imageInput\n",
      "transform grey\n",
      "transform edge\n",
      "(50L, 50L)\n",
      "http://www.loc.gov/rr/scitech/subjectguides/images/tesla-new.jpg\n",
      "transform grey\n",
      "transform edge\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd660e4b089801fe7e3d9/1458152617516/SciSource_BK0929.jpg?format=750w\n",
      "transform grey\n",
      "transform edge\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd28be4b0c47638e2f540/1458152692173/SciSource_BN4337.jpg?format=750w\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/5400dbd4e4b0fc8cd2ef213e/1458152745999/SciSource_BU1440.jpg?format=750w\n",
      "input\n",
      "transform grey\n",
      "(50L, 50L)\n",
      "http://www.loc.gov/rr/scitech/subjectguides/images/tesla-new.jpg\n",
      "transform grey\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd660e4b089801fe7e3d9/1458152617516/SciSource_BK0929.jpg?format=750w\n",
      "transform grey\n",
      "(50L, 50L)\n",
      "https://static1.squarespace.com/static/51cdd10de4b08819bd7bc9b4/525d89c2e4b0f8245cabfc96/53cfd28be4b0c47638e2f540/1458152692173/SciSource_BN4337.jpg?format=750w\n",
      "output\n",
      "(3L, 1L, 50L, 50L)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdc2a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "global name 'image_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-08d89dcc107f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mstoreResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mrunPersona\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersona\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-08d89dcc107f>\u001b[0m in \u001b[0;36mrunPersona\u001b[0;34m(persona)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[1;31m#store test results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mstoreResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mrunPersona\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersona\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-08d89dcc107f>\u001b[0m in \u001b[0;36mstoreResults\u001b[0;34m(input_data, output_data, dataType)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimgIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGreys_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGreys_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'image_index' is not defined"
     ]
    }
   ],
   "source": [
    "#persona definition\n",
    "persona_definition_path = os.path.abspath(os.path.join('..', '..', 'Personas', 'personaDefinition_pb2.py'))\n",
    "print (persona_definition_path)\n",
    "#import persona proto modules\n",
    "persona = imp.load_source('Persona', persona_definition_path).Persona()\n",
    "\n",
    "#load persona\n",
    "personaName = \"Khandhasamy\"\n",
    "personaCategory = ['Artist', 'Portraits', 'sketchToGreyImage'] \n",
    "personaPath = os.path.join('..', '..', 'Personas')\n",
    "for category in personaCategory:\n",
    "    personaPath = os.path.join(personaPath, category)\n",
    "\n",
    "#persona file\n",
    "persona_abs_path = os.path.abspath(os.path.join(personaPath, personaName , personaName + '.bin'))\n",
    "f = open(persona_abs_path, \"rb\")\n",
    "persona.ParseFromString(f.read())\n",
    "\n",
    "def getInformationSource(persona, layer):\n",
    "    for environment in persona.age.environments:\n",
    "        for information in environment.informations:\n",
    "            for informationConnectedLayerName in information.connectedLayerName:\n",
    "                if (layer.layerName == informationConnectedLayerName):\n",
    "                    #print (information.informationSource)\n",
    "                    return getExtractor(information)\n",
    "\n",
    "def getExtractor(information):\n",
    "    #information definition\n",
    "    information_definition_path = os.path.abspath(os.path.join('..', '..', 'Environment', information.informationSource + \"_pb2.py\"))\n",
    "    informationModule = imp.load_source('Information', information_definition_path).Information()  \n",
    "    information_file_path = os.path.abspath(os.path.join('..', '..', 'Environment', information.informationSource + \".bin\"))\n",
    "    informationFile = open(information_file_path, \"rb\")\n",
    "    informationModule.ParseFromString(informationFile.read())\n",
    "    #load extractor\n",
    "    information_extractor_path = os.path.abspath(os.path.join('..', '..', 'Environment/Informations/Process/Extract/' + informationModule.extractor + \".py\"))\n",
    "    extractorModule = imp.load_source(informationModule.extractor, information_extractor_path).ImageURLExtractor(informationModule)\n",
    "    #print (informationModule.extractor)\n",
    "    return extractorModule\n",
    "\n",
    "def storeResults(input_data, output_data, dataType):\n",
    "    if dataType == \"image\":\n",
    "        print (output_data.shape)\n",
    "        print (output_data.shape[0])\n",
    "        for imgIndex in range(output_data.shape[0]):\n",
    "            plt.imshow(input_data[imgIndex][0]*255, cmap = cm.Greys_r)\n",
    "            plt.show()\n",
    "            plt.imshow(output_data[imgIndex][0]*255, cmap = cm.Greys_r)\n",
    "            plt.show()\n",
    "\n",
    "LAYER_CONVOLUTION = \"layerConvolution\"\n",
    "LAYER_ACTIVATION = \"layerActivation\"\n",
    "LAYER_DROPOUT = \"layerDropout\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "def runPersona(persona):\n",
    "    x_train_data = None\n",
    "    y_train_data = None\n",
    "    x_test_data = None\n",
    "    input_shape = None\n",
    "    batch_size = None\n",
    "\n",
    "    for dna in persona.DNAs:\n",
    "        for inputLayer in dna.inputs:\n",
    "            print (inputLayer.layerName)\n",
    "            inputTransform = inputLayer.inputTransform\n",
    "            #get information source\n",
    "            information = getInformationSource(persona, inputLayer)\n",
    "\n",
    "            x_train_data = information.getTrainingData(inputTransform)\n",
    "            x_test_data = information.getTestData(inputTransform)\n",
    "            print (\"input\")\n",
    "            \n",
    "#         for layer in dna.layers:\n",
    "#             if (LAYER_CONVOLUTION == layer.WhichOneof(\"SubLayer\")):\n",
    "#                 nb_filters = layer.layerConvolution.filters\n",
    "#                 convDimension = layer.layerConvolution.convolutionDimension\n",
    "#                 borderMode = layer.layerConvolution.borderMode\n",
    "#                 kernelSize = layer.layerConvolution.kernelSize\n",
    "#                 inputShape = layer.layerConvolution.inputShape\n",
    "#                 if K.image_dim_ordering() == 'th':\n",
    "#                     conv_input_shape = (inputShape[0], inputShape[1], inputShape[2])\n",
    "#                 else:\n",
    "#                     conv_input_shape = (inputShape[1], inputShape[2], inputShape[0])\n",
    "#                 if convDimension == 2:\n",
    "#                     model.add(Convolution2D(nb_filters, kernelSize[0], kernelSize[1],\n",
    "#                         border_mode=borderMode,\n",
    "#                         input_shape=conv_input_shape))\n",
    "#                     print (\"conv2D\")\n",
    "#             if (LAYER_ACTIVATION == layer.WhichOneof(\"SubLayer\")):  \n",
    "#                 activationType = layer.layerActivation.activationType\n",
    "#                 model.add(Activation(activationType))\n",
    "#                 print (\"activation\")\n",
    "#             if (LAYER_DROPOUT == layer.WhichOneof(\"SubLayer\")):\n",
    "#                 dropoutPercentage = layer.layerDropout.dropPercentage\n",
    "#                 model.add(Dropout(dropoutPercentage))\n",
    "#                 print (\"dropout\")\n",
    "                \n",
    "        for outputLayer in dna.outputs:\n",
    "            #print (outputLayer.layerName)\n",
    "            inputTransform = outputLayer.inputTransform\n",
    "            #get information source\n",
    "            information = getInformationSource(persona, outputLayer)\n",
    "            #train data\n",
    "            y_train_data = information.getTrainingData(inputTransform)\n",
    "            print (\"output\")\n",
    "    \n",
    "#     #compile model\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "    \n",
    "#     print (x_train_data.shape)\n",
    "#     print (y_train_data.shape)\n",
    "\n",
    "    \n",
    "#     #learning\n",
    "#     batch_size = persona.age.learningBatchSize\n",
    "#     print (batch_size)\n",
    "#     nb_epoch = 200\n",
    "#     model.fit(x_train_data, y_train_data, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "#           verbose=1, validation_data=(x_train_data, y_train_data))\n",
    "    \n",
    "#     #output for action data\n",
    "#     y_test_data = model.predict(x_test_data)\n",
    "\n",
    "    #store test results\n",
    "    storeResults(x_train_data, y_train_data, \"image\")\n",
    "    \n",
    "runPersona(persona)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 100, 100\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 1\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X_train_data = np.random.random((6,1, img_rows, img_cols))\n",
    "# Y_train_data = np.random.random((6,1, img_rows, img_cols))\n",
    "\n",
    "# with open(\"../../Environment/Informations/Category/Portraits/trainImages/images.txt\") as f:\n",
    "#     infoFileContents = f.readlines()\n",
    "#     for l in range(len(infoFileContents)):\n",
    "#         infoLine = infoFileContents[l].lstrip().rstrip()\n",
    "        \n",
    "#         print (infoLine)\n",
    "#         response = requests.get(infoLine)\n",
    "#         trainInpImg = Image.open(BytesIO(response.content))\n",
    "#         trainInpGrayImg = trainInpImg.convert(\"L\")\n",
    "#         trainInpGrayImg = trainInpGrayImg.resize((img_rows,img_cols), PIL.Image.ANTIALIAS)\n",
    "#         trainInpGreyImgArray = np.asarray(trainInpGrayImg, dtype=np.float32)\n",
    "#         Y_train_data[l,0,:,:] = trainInpGreyImgArray\n",
    "        \n",
    "#         trainInpEdgeImg = trainInpImg.convert(\"L\")\n",
    "#         trainInpEdgeImg = trainInpEdgeImg.resize((img_rows,img_cols), PIL.Image.ANTIALIAS)\n",
    "#         trainInpEdgeImg = trainInpEdgeImg.filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "#         trainInpEdgeImgArray = np.asarray(trainInpEdgeImg, dtype=np.float32)\n",
    "#         X_train_data[l,0,:,:] = trainInpEdgeImgArray\n",
    "\n",
    "# X_test_data = np.random.random((2,1, img_rows, img_cols))\n",
    "# Y_test_data = np.random.random((2,1, img_rows, img_cols))        \n",
    "\n",
    "# with open(\"../../Environment/Informations/Category/Portraits/testImages/images.txt\") as f:\n",
    "#     infoFileContents = f.readlines()\n",
    "#     for l in range(len(infoFileContents)):\n",
    "#         infoLine = infoFileContents[l].lstrip().rstrip()\n",
    "        \n",
    "#         print (infoLine)\n",
    "#         response = requests.get(infoLine)\n",
    "#         trainInpImg = Image.open(BytesIO(response.content))\n",
    "#         trainInpGrayImg = trainInpImg.convert(\"L\")\n",
    "#         trainInpGrayImg = trainInpGrayImg.resize((img_rows,img_cols), PIL.Image.ANTIALIAS)\n",
    "#         trainInpGreyImgArray = np.asarray(trainInpGrayImg, dtype=np.float32)\n",
    "#         Y_test_data[l,0,:,:] = trainInpGreyImgArray\n",
    "        \n",
    "#         trainInpEdgeImg = trainInpImg.convert(\"L\")\n",
    "#         trainInpEdgeImg = trainInpEdgeImg.resize((img_rows,img_cols), PIL.Image.ANTIALIAS)\n",
    "#         trainInpEdgeImg = trainInpEdgeImg.filter(ImageFilter.FIND_EDGES)\n",
    "#         trainInpEdgeImgArray = np.asarray(trainInpEdgeImg, dtype=np.float32)\n",
    "#         X_test_data[l,0,:,:] = trainInpEdgeImgArray\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_data = X_train_data.astype('float32')\n",
    "X_train_data /= 255\n",
    "print('X_train shape:', X_train_data.shape)\n",
    "print(X_train_data.shape[0], 'train samples')\n",
    "Y_train_data = Y_train_data.astype('float32')\n",
    "Y_train_data /= 255\n",
    "print('Y_train shape:', Y_train_data.shape)\n",
    "print(Y_train_data.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if K.image_dim_ordering() == 'th':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters*100, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='same',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Convolution2D(nb_filters*100, kernel_size[0], kernel_size[1],\n",
    "                         border_mode='same',\n",
    "                         input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Convolution2D(nb_filters*100, kernel_size[0], kernel_size[1],\n",
    "                         border_mode='same',\n",
    "                         input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Convolution2D(nb_filters*100, kernel_size[0], kernel_size[1],\n",
    "                         border_mode='same',\n",
    "                         input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                         border_mode='same',\n",
    "                         input_shape=input_shape))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_data, Y_train_data, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test_data, Y_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train_data, Y_train_data, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_data = model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_image = np.concatenate((X_train_data[0][0]*255, Y_train_data[0][0]*255), axis=1)\n",
    "plt.imshow(X_test_data[0][0]*255, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "plt.imshow(pred_data[0][0]*255, cmap = cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainInpGrayImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainInpEdgeImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prdImg = Image.fromarray(pred_data[0][0], 'L')\n",
    "prdImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
