{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 1\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "X_train_data = np.random.random((3,1, img_rows, img_cols))\n",
    "X_train_data[0,:,:,:] = X_train[0,:,:,:]\n",
    "X_train_data[1,:,:,:] = X_train[1,:,:,:]\n",
    "X_train_data[2,:,:,:] = X_train[2,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3L, 1L, 28L, 28L)\n",
      "3 train samples\n"
     ]
    }
   ],
   "source": [
    "X_train_data = X_train_data.astype('float32')\n",
    "X_train_data /= 255\n",
    "print('X_train shape:', X_train_data.shape)\n",
    "print(X_train_data.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters*100, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='same',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                         border_mode='same',\n",
    "                         input_shape=input_shape))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 3 samples\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s - loss: 0.3062 - val_loss: 0.2781\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s - loss: 0.2781 - val_loss: 0.2588\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s - loss: 0.2588 - val_loss: 0.2446\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s - loss: 0.2446 - val_loss: 0.2333\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s - loss: 0.2333 - val_loss: 0.2240\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s - loss: 0.2240 - val_loss: 0.2158\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s - loss: 0.2158 - val_loss: 0.2087\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s - loss: 0.2087 - val_loss: 0.2024\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s - loss: 0.2024 - val_loss: 0.1966\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s - loss: 0.1966 - val_loss: 0.1913\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s - loss: 0.1913 - val_loss: 0.1864\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s - loss: 0.1864 - val_loss: 0.1818\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s - loss: 0.1818 - val_loss: 0.1775\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s - loss: 0.1775 - val_loss: 0.1733\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s - loss: 0.1733 - val_loss: 0.1694\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s - loss: 0.1694 - val_loss: 0.1656\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s - loss: 0.1656 - val_loss: 0.1620\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s - loss: 0.1620 - val_loss: 0.1585\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s - loss: 0.1585 - val_loss: 0.1551\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s - loss: 0.1551 - val_loss: 0.1519\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s - loss: 0.1519 - val_loss: 0.1487\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s - loss: 0.1487 - val_loss: 0.1457\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s - loss: 0.1457 - val_loss: 0.1427\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s - loss: 0.1427 - val_loss: 0.1399\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s - loss: 0.1399 - val_loss: 0.1371\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s - loss: 0.1371 - val_loss: 0.1343\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s - loss: 0.1343 - val_loss: 0.1316\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s - loss: 0.1316 - val_loss: 0.1290\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s - loss: 0.1290 - val_loss: 0.1263\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s - loss: 0.1263 - val_loss: 0.1237\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s - loss: 0.1237 - val_loss: 0.1212\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s - loss: 0.1212 - val_loss: 0.1186\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s - loss: 0.1186 - val_loss: 0.1161\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s - loss: 0.1161 - val_loss: 0.1136\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s - loss: 0.1136 - val_loss: 0.1112\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s - loss: 0.1112 - val_loss: 0.1088\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s - loss: 0.1088 - val_loss: 0.1064\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s - loss: 0.1064 - val_loss: 0.1041\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s - loss: 0.1041 - val_loss: 0.1018\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s - loss: 0.1018 - val_loss: 0.0995\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s - loss: 0.0995 - val_loss: 0.0972\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s - loss: 0.0972 - val_loss: 0.0951\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s - loss: 0.0951 - val_loss: 0.0931\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s - loss: 0.0931 - val_loss: 0.0915\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s - loss: 0.0915 - val_loss: 0.0933\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s - loss: 0.0933 - val_loss: 0.0909\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s - loss: 0.0909 - val_loss: 0.0891\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s - loss: 0.0891 - val_loss: 0.0880\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s - loss: 0.0880 - val_loss: 0.0869\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s - loss: 0.0869 - val_loss: 0.0860\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s - loss: 0.0860 - val_loss: 0.0858\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s - loss: 0.0858 - val_loss: 0.0848\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s - loss: 0.0848 - val_loss: 0.0839\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s - loss: 0.0839 - val_loss: 0.0835\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s - loss: 0.0835 - val_loss: 0.0827\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s - loss: 0.0827 - val_loss: 0.0818\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s - loss: 0.0818 - val_loss: 0.0811\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s - loss: 0.0811 - val_loss: 0.0805\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s - loss: 0.0805 - val_loss: 0.0800\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s - loss: 0.0800 - val_loss: 0.0799\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s - loss: 0.0799 - val_loss: 0.0794\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s - loss: 0.0794 - val_loss: 0.0791\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s - loss: 0.0791 - val_loss: 0.0790\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s - loss: 0.0790 - val_loss: 0.0789\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s - loss: 0.0789 - val_loss: 0.0785\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s - loss: 0.0785 - val_loss: 0.0784\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s - loss: 0.0784 - val_loss: 0.0781\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s - loss: 0.0781 - val_loss: 0.0796\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s - loss: 0.0796 - val_loss: 0.0777\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s - loss: 0.0777 - val_loss: 0.0778\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s - loss: 0.0778 - val_loss: 0.0773\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s - loss: 0.0773 - val_loss: 0.0775\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s - loss: 0.0775 - val_loss: 0.0774\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s - loss: 0.0774 - val_loss: 0.0772\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s - loss: 0.0772 - val_loss: 0.0786\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s - loss: 0.0786 - val_loss: 0.0775\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s - loss: 0.0775 - val_loss: 0.0772\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s - loss: 0.0772 - val_loss: 0.0771\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s - loss: 0.0771 - val_loss: 0.0773\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s - loss: 0.0773 - val_loss: 0.0770\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s - loss: 0.0770 - val_loss: 0.0766\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s - loss: 0.0766 - val_loss: 0.0768\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s - loss: 0.0768 - val_loss: 0.0767\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s - loss: 0.0767 - val_loss: 0.0763\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s - loss: 0.0763 - val_loss: 0.0762\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s - loss: 0.0762 - val_loss: 0.0822\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s - loss: 0.0822 - val_loss: 0.0780\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s - loss: 0.0780 - val_loss: 0.0762\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s - loss: 0.0762 - val_loss: 0.0761\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s - loss: 0.0761 - val_loss: 0.0760\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s - loss: 0.0760 - val_loss: 0.0763\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s - loss: 0.0763 - val_loss: 0.0762\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s - loss: 0.0762 - val_loss: 0.0759\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s - loss: 0.0759 - val_loss: 0.0761\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s - loss: 0.0761 - val_loss: 0.0758\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s - loss: 0.0758 - val_loss: 0.0778\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s - loss: 0.0778 - val_loss: 0.0759\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s - loss: 0.0759 - val_loss: 0.0759\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s - loss: 0.0759 - val_loss: 0.0758\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s - loss: 0.0758 - val_loss: 0.0757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10b2e710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_data, X_train_data, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_train_data, X_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0756545886397\n",
      "Test accuracy: 0.0756545886397\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train_data, X_train_data, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " pred_data = model.predict(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADKCAYAAAC11LviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEp9JREFUeJzt3XuMldW5x/Hf4wiVWwVvhICiVkxL1OIllGBLtVaCWG+9\nRRstp1GpqVKa9qBYk1ZtbIjFgvXSlgotDdaGatGpUQl6SPC0tjBwEFGqGONEKUKoRfECw8Bz/pjX\ndmqf5b7M3ntm1nw/CZm9f3uz97OG4eHl3etdy9xdAIDe74DuLgAAUBs0dADIBA0dADJBQweATNDQ\nASATNHQAyAQNHQAyQUMHgEzQ0AEgEwd25Teb2RRJt0tqknSPu88p8XwuSwWAyu1w98NLPanqI3Qz\na5J0l6RzJI2VdImZja329QAASa3lPKkrp1zGS3rR3V9y9zZJv5V0QRdeDwDQBV1p6CMlvdLp/qtF\n9m/MbLqZtZhZSxfeCwBQQpfOoZfD3RdIWiBxDh0A6qkrR+hbJB3Z6f6oIgMAdIOuNPQ1ksaY2TFm\n1l/SxZKaa1MWAKBSVZ9ycfd2M7tG0nJ1TFtc5O7P1qwyAEBFrJE7FnEOHQCqstbdTyv1JK4UBYBM\n0NABIBM0dADIBA0dADJBQweATNDQASATNHQAyAQNHQAyQUMHgEzUfbVFAKjWoEGDwnzv3r1h3tbW\nVs9yejyO0AEgEzR0AMgEDR0AMkFDB4BM0NABIBPMcsnQ+PHjw3zmzJlhPnXq1DB/5JFHwvz2228P\n89WrV5dRHfqyU089NcyvuOKKMJ84cWKYp37W7r///jBfvnx5GdX1fhyhA0AmaOgAkAkaOgBkgoYO\nAJmgoQNAJszdq//NZi9L2iVpn6T2UrtSm1n1b4b/kJox0NzcHOYDBgyoyfu+++67YT5y5MiavD56\nvzPPPDPM77rrrjD/yEc+Euap/pT6GdywYUOYT5kypaLX6YHWluqvUm2mLZ7p7jtq8DoAgC7glAsA\nZKKrDd0lPW5ma81sevQEM5tuZi1m1tLF9wIAfICunnL5pLtvMbMjJK0ws7+6+6rOT3D3BZIWSJxD\nB4B66tIRurtvKb5ul7RMUnzNOQCg7qo+QjezQZIOcPddxe3Jkm6uWWX4p9R6FkuWLAnzgQMHhnlq\nxsDu3bvDvL29PcwHDx4c5pMmTQrzp556KsxTu86g90j9mc+fPz/Mx4wZE+apn7XULJRUftxxx4X5\n5z//+TC/9957w7y36sopl+GSlpnZe6/zG3d/rCZVAQAqVnVDd/eXJH28hrUAALqAaYsAkAkaOgBk\ngoYOAJno0louFb8Z89AlpddUmTBhQpjfc889YT5s2LAwLz6o/g+pP+uXXnopzOfNmxfmd9xxR0Xv\nm5rxcNNNN4U5uk9TU1OYX3TRRWF+4403hnlqNkvqZ3D//v1hvnnz5jB/9NFHw/yyyy4L89SMqrlz\n54b5nXfeGebdqKy1XDhCB4BM0NABIBM0dADIBA0dADJBQweATNRigwtU6Je//GWYT548ucGVdDj2\n2GPDfNCgQWG+cePGMD/xxBPD/KSTTqquMDTcnDlzwvxrX/tamA8dOjTMU+sDpWabDBkyJMyHDx8e\n5qmZWevWrQvzs846K8xTu371VhyhA0AmaOgAkAkaOgBkgoYOAJmgoQNAJpjlUkfjx8c78n3qU58K\n89RaKCmp2SYPP/xwmM+ePTvMd+7cGeZr1qwJ8zfeeCPMf/7zn4c5ep4LL7wwzL/yla+E+aGHHhrm\nb7/9dpivWrUqzFtbW8P8S1/6Uphv27YtzP/0pz+F+d/+9rcwT62TdNhhh4V5b8UROgBkgoYOAJmg\noQNAJmjoAJCJkg3dzBaZ2XYz29gpO8TMVpjZ5uJrvNMCAKBhSu5YZGaTJL0l6dfufkKR3SrpdXef\nY2azJQ1z9+tKvlmmOxal1oNobm4O89SORSktLS1hntpF5pxzzgnzsWPHhvndd98d5jt27Cijun/5\nxz/+EeZ79uwJ8/PPPz/MV69eXdH7Iu0Tn/hEmC9atCjMP/rRj4Z5W1tbmD/++ONhnlr7JbXL1rnn\nnhvmjzzySJi/8MILYX7ggfHEvdTsl3feeSfMv/rVr4Z5avZOA9RmxyJ3XyXp9ffFF0haXNxeLCme\nAwUAaJhqz6EPd/etxe3XJMVLogEAGqbLFxa5u3/QqRQzmy5pelffBwDwwao9Qt9mZiMkqfi6PfVE\nd1/g7qeVc/4HAFC9aht6s6Rpxe1pkh6qTTkAgGqVPOViZvdJOkPSYWb2qqTvS5ojaamZXS6pVdKX\n61lkT3H88ceHeWqNlIEDB4b5rl27wjw1S2Tx4sVhnlpH4/777w/z7tK/f/8wnzVrVpin1vVA2pgx\nY8L8e9/7XkXPT63rk1o3aOHChWGemiGVyufPnx/mldq3b19F+eGHHx7mX/jCF8K8G2e5lKVkQ3f3\nSxIPxXs6AQC6BVeKAkAmaOgAkAkaOgBkgoYOAJlgx6JAalbGT37ykzBP7Uy0e/fuMJ8xY0aYP/nk\nk2Fe6dovvcWoUaO6u4Rep1+/fmH+gx/8IMw/+9nPhvmWLVvC/IYbbgjzRx99NMxTM7O6y4c+9KEw\n37t3b5invp8f+9jHalZTI3GEDgCZoKEDQCZo6ACQCRo6AGSChg4AmWCWS2DChAlhnprNkpLa9WTF\nihUV1wRI0nnnnRfmZ599dpindou69tprw/x3v/tddYVlJrXzUU/HEToAZIKGDgCZoKEDQCZo6ACQ\nCRo6AGSid36UW2c/+tGPwtzMwjy1m0tfm82S+v7U6vl9yUEHHRTmV111VZgffPDBYb5y5cowz3U2\ny/79+8P8gAPiY9dU3t7eXrOaGokjdADIBA0dADJBQweATNDQASATJRu6mS0ys+1mtrFTdqOZbTGz\n9cWvqfUtEwBQSjmzXH4l6U5Jv35fPs/d59a8ogb64he/GObHHHNMmLt7mDc3N9espt4s9f1J5U8/\n/XQ9y+nVJk+eHOannnpqmLe1tYV5X/vZHDZsWJindiZK7WS0evXqmtXUSCWP0N19laTXG1ALAKAL\nunIOfYaZbShOycT/LAIAGqbahv5TScdKGidpq6TbUk80s+lm1mJmLVW+FwCgDFU1dHff5u773H2/\npF9ISi4U7u4L3P00dz+t2iIBAKVV1dDNbESnuxdJiq99BwA0TMlZLmZ2n6QzJB1mZq9K+r6kM8xs\nnCSX9LKkr9exxrpJrZeR2q3kzTffDPMlS5bUrKaepH///mF+yy23VPQ6GzZsCPNvf/vbFdfUVwwZ\nMiTMm5qawnzHjh1h/uCDD9aspp4k9Xd01qxZYT548OAwf+qpp8J87tzeOYGvZEN390uCeGEdagEA\ndAFXigJAJmjoAJAJGjoAZIKGDgCZYMeiCqR2Mdm6dWuDK6mt1GyWm2++Ocwvv/zyMH/99XiFiHnz\n5oX522+/XUZ16Cy1y1Pqe//KK6/Us5y6GzBgQJjfeuutYX7ppZeGeWtra5indifbuXNnGdX1PByh\nA0AmaOgAkAkaOgBkgoYOAJmgoQNAJpjlUoHly5d3dwldktrtZvbs2WF+1llnhfkf//jHMD/vvPOq\nKwz/IbXL07vvvhvmL7zwQj3LqbuJEyeG+Q033BDm48fHC7w+8cQTYX7NNdeE+WuvvVZGdb0HR+gA\nkAkaOgBkgoYOAJmgoQNAJmjoAJCJPj3LJbUuRiqfMmVKPcupmeuuuy7Mv/nNb4b5wIEDw/yxxx4L\n80suifY8QS0dcEB8rJVad2f06NFhntr5aNeuXdUVVqZhw4aFeWq2yZVXXhnmBx98cJinZpxNmzYt\nzFOzg3LDEToAZIKGDgCZoKEDQCZo6ACQiZIN3cyONLOVZvacmT1rZjOL/BAzW2Fmm4uv8acgAICG\nKGeWS7uk77j7OjMbImmtma2Q9F+SnnD3OWY2W9JsSfH0ih4qtV5GKh86dGiY33333WG+cOHCMN++\nfXuYf/rTnw7z1C4sY8aMCfNDDjkkzP/+97+H+Z///OcwT40L9Zf6GWxqagrz4447LsxnzZoV5g88\n8ECYp3Y+mjRpUpin1u855ZRTwvyII44I871794b5Qw89FOa33XZbmPeV2SwpJY/Q3X2ru68rbu+S\ntEnSSEkXSFpcPG2xpAvrVSQAoLSKzqGb2dGSTpb0F0nD3f29zTRfkzS8ppUBACpS9oVFZjZY0gOS\nvuXub3a++Mbd3czC/yOa2XRJ07taKADgg5V1hG5m/dTRzO91998X8TYzG1E8PkJSeGLY3Re4+2nu\nflotCgYAxMqZ5WKSFkra5O4/7vRQs6T3rrOdJin+9AIA0BDlnHI5XdJlkp4xs/VF9l1JcyQtNbPL\nJbVK+nJ9Suw5Umu8XHzxxWE+derUME99Ej98eG0+hnj++efDfOXKlWF+/fXX1+R9UTttbW1hvmfP\nnjBPzWy66qqrwrzS3aWOOuqoMB88eHCYp+pfv359mKdm3fzsZz8L8927d4d5X1eyobv7/0qKO5kU\n71EGAGg4rhQFgEzQ0AEgEzR0AMgEDR0AMtGndyxKzfp48cUXwzy1XkZKareVD3/4wxW9zltvvRXm\nf/jDH8L86quvruj10fOsWbMmzFtaWsJ84sSJYZ6a/ZLK9+/fH+apWSutra1hvnTp0jD/4Q9/GObv\nvPNOmKMyHKEDQCZo6ACQCRo6AGSChg4AmaChA0AmLLUzSl3eLLHEbk8zYsSIME/NHvnGN74R5qm1\nX1Lf8yVLloT5HXfcEeabN28Oc+Rr9OjRYT5jxowwT60zlFqDZefOnWG+bNmyMF+wYEGYb9q0KcxR\ntbXlrFjLEToAZIKGDgCZoKEDQCZo6ACQCRo6AGSCWS5AH9TU1BTmqZlZ7e3t9SwHpTHLBQD6Eho6\nAGSChg4AmaChA0AmSjZ0MzvSzFaa2XNm9qyZzSzyG81si5mtL35NrX+5AICUcnYsapf0HXdfZ2ZD\nJK01sxXFY/PcfW79ygNQD/v27evuElAHJRu6u2+VtLW4vcvMNkkaWe/CAACVqegcupkdLelkSX8p\nohlmtsHMFpnZsBrXBgCoQNkN3cwGS3pA0rfc/U1JP5V0rKRx6jiCvy3x+6abWYuZxbvbAgBqoqwr\nRc2sn6SHJS139x8Hjx8t6WF3P6HE63ClKABUrjZXilrHtcALJW3q3MzNrPMuEBdJ2lhNlQCA2ihn\nlsvpki6T9IyZrS+y70q6xMzGSXJJL0v6el0qBACUhcW5AKDnY3EuAOhLaOgAkAkaOgBkgoYOAJmg\noQNAJmjoAJAJGjoAZIKGDgCZoKEDQCZo6ACQiXLWcqmlHZJai9uHFff7Csabr740VonxdofR5Typ\noWu5/Nsbm7WUszZBLhhvvvrSWCXG25NxygUAMkFDB4BMdGdDX9CN790dGG+++tJYJcbbY3XbOXQA\nQG1xygUAMtHwhm5mU8zseTN70cxmN/r9683MFpnZdjPb2Ck7xMxWmNnm4uuw7qyxlszsSDNbaWbP\nmdmzZjazyLMcs5kdZGarzezpYrw3FXmW45UkM2sys/8zs4eL+zmP9WUze8bM1ptZS5H1mvE2tKGb\nWZOkuySdI2msOvYlHdvIGhrgV5KmvC+bLekJdx8j6Ynifi7aJX3H3cdKmiDp6uLPNNcx75H0GXf/\nuKRxkqaY2QTlO15JmilpU6f7OY9Vks5093Gdpir2mvE2+gh9vKQX3f0ld2+T9FtJFzS4hrpy91WS\nXn9ffIGkxcXtxZIubGhRdeTuW919XXF7lzr+4o9UpmP2Dm8Vd/sVv1yZjtfMRkk6V9I9neIsx/oB\nes14G93QR0p6pdP9V4ssd8PdfWtx+zVJw7uzmHoxs6MlnSzpL8p4zMUpiPWStkta4e45j3e+pGsl\n7e+U5TpWqeMf58fNbK2ZTS+yXjPeRl/63+e5u5tZdlOLzGywpAckfcvd3zSzfz6W25jdfZ+kcWY2\nVNIyMzvhfY9nMV4z+5yk7e6+1szOiJ6Ty1g7+aS7bzGzIyStMLO/dn6wp4+30UfoWyQd2en+qCLL\n3TYzGyFJxdft3VxPTZlZP3U083vd/fdFnPWYJcndd0paqY7PTHIc7+mSzjezl9VxevQzZrZEeY5V\nkuTuW4qv2yUtU8dp4l4z3kY39DWSxpjZMWbWX9LFkpobXEN3aJY0rbg9TdJD3VhLTVnHofhCSZvc\n/cedHspyzGZ2eHFkLjMbIOlsSX9VhuN19+vdfZS7H62Ov6v/4+6XKsOxSpKZDTKzIe/dljRZ0kb1\novE2/MIiM5uqjvNyTZIWufstDS2gzszsPklnqGOFtm2Svi/pQUlLJR2ljtUmv+zu7//gtFcys09K\nelLSM/rXedbvquM8enZjNrOT1PHBWJM6DoiWuvvNZnaoMhzve4pTLv/t7p/Ldaxmdqw6jsqljtPR\nv3H3W3rTeLlSFAAywZWiAJAJGjoAZIKGDgCZoKEDQCZo6ACQCRo6AGSChg4AmaChA0Am/h8Xmmkl\nfd4eygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1576de10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image = np.concatenate((X_train_data[1][0]*255, pred_data[1][0]*255), axis=1)\n",
    "plt.imshow(plot_image, cmap = cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
